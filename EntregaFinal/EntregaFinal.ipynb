{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKeClKyyVQZ8"
      },
      "source": [
        "## Análise e Classificação de Reservas de Hotel  \n",
        "Este notebook contém uma análise exploratória e um modelo de classificação aplicado a um conjunto de dados de reservas de hotel. O objetivo é entender os padrões presentes nas reservas e prever o status das reservas com base em diversas características.  \n",
        "  \n",
        "O notebook está dividido em várias seções, cada uma realizando uma etapa específica do processo de análise e modelagem:  \n",
        "  \n",
        "1) Preparação dos Dados: Carregamento dos dados, identificação de variáveis categóricas e pré-processamento.\n",
        "2) Análise Exploratória: Exploração das características dos dados e visualização de padrões.\n",
        "3) Engenharia de Recursos: Criação de variáveis dummy para características categóricas e codificação de rótulos.\n",
        "4) Modelagem: Treinamento de um modelo de árvore de decisão para prever o status das reservas.\n",
        "5) Avaliação do Modelo: Avaliação da precisão do modelo e análise da matriz de confusão.\n",
        "  \n",
        "Cada célula de código é acompanhada de comentários explicativos para facilitar a compreensão do processo realizado em cada etapa.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD7_wujIVQZ9"
      },
      "source": [
        "* Importação das bibliotecas Pandas e NumPy.\n",
        "* Leitura de um arquivo CSV chamado 'Hotel Reservations.csv' e armazenamento dos dados em um DataFrame chamado df.\n",
        "* Exibição dos cinco primeiros registros do DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ADMNc32u5bdn",
        "outputId": "70f12063-4774-48d8-9021-211b1dd6c744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../Data/Hotel Reservations.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a02c5923dd4f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/Hotel Reservations.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/Hotel Reservations.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df=pd.read_csv('../Data/Hotel Reservations.csv', sep=',')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CakC1WtVQZ-"
      },
      "source": [
        "* Iteração sobre as colunas do DataFrame.\n",
        "* Para cada coluna, imprime o nome da coluna e o número de valores únicos presentes nela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIiDIFbXtfkr"
      },
      "outputs": [],
      "source": [
        "for c in df.columns:\n",
        "    print(f\"{c:40s} - {df[c].nunique():>5d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJA3cpqVQZ-"
      },
      "source": [
        "* Remoção da coluna \"Booking_ID\" do DataFrame usando o método drop.\n",
        "* Exibição do DataFrame após a remoção da coluna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wysmSE0pVQZ-"
      },
      "outputs": [],
      "source": [
        "df = df.drop(\"Booking_ID\", axis = 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f085ad1VQZ_"
      },
      "source": [
        "* Criação de variáveis dummy para as colunas categóricas do DataFrame usando a função `pd.get_dummies`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmzssObeVQZ_"
      },
      "outputs": [],
      "source": [
        "typeofmealplaDummies = pd.get_dummies(df[\"type_of_meal_plan\"], prefix = \"type_of_meal_plan\")\n",
        "roomtypereservedDummies = pd.get_dummies(df[\"room_type_reserved\"], prefix = \"room_type_reserved\")\n",
        "marketsegmenttypeDummies = pd.get_dummies(df[\"market_segment_type\"], prefix = \"market_segment_type\")\n",
        "requiredcarparkingspaceDummies = pd.get_dummies(df[\"required_car_parking_space\"], prefix = \"required_car_parking_space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em_48YSCVQZ_"
      },
      "source": [
        "* Concatenação das variáveis dummy criadas anteriormente ao DataFrame original ao longo do eixo das colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0DpGfR4VQZ_"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df, typeofmealplaDummies], axis = 1)\n",
        "df = pd.concat([df, roomtypereservedDummies], axis = 1)\n",
        "df = pd.concat([df, marketsegmenttypeDummies], axis = 1)\n",
        "df = pd.concat([df, requiredcarparkingspaceDummies], axis = 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6-sN98hVQZ_"
      },
      "source": [
        "* Codificação da coluna \"_booking_status_\" usando o LabelEncoder do `scikit-learn` para converter os rótulos em números inteiros.\n",
        "* Exibição do DataFrame após a codificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ccenrg5VQZ_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "df[\"booking_status\"] = LabelEncoder().fit_transform(df[\"booking_status\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YrnL-7rVQZ_"
      },
      "source": [
        "* Remoção das colunas \"type_of_meal_plan\", \"room_type_reserved\" e \"market_segment_type\" do DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJCbHS6IVQZ_"
      },
      "outputs": [],
      "source": [
        "df = df.drop(\"type_of_meal_plan\", axis = 1)\n",
        "df = df.drop(\"room_type_reserved\", axis = 1)\n",
        "df = df.drop(\"market_segment_type\", axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8B4Y3wVQZ_"
      },
      "source": [
        "* Separação do DataFrame em conjuntos de características (X) e rótulos (y).\n",
        "* Divisão dos conjuntos de treinamento e teste usando `train_test_split` do `scikit-learn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMxg_dc7VQZ_"
      },
      "outputs": [],
      "source": [
        "X = df.drop(\"booking_status\", axis = 1)\n",
        "y = df[\"booking_status\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgpVxU0uVQZ_"
      },
      "source": [
        "* Cálculo da correlação entre cada característica e o rótulo (\"booking_status\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K-Ew0vKVQaA"
      },
      "outputs": [],
      "source": [
        "df.corr()['booking_status']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B98oTrjVQaA"
      },
      "source": [
        "## Árvore de Decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estamos utilizando o algoritmo Árvore de Decisão para realizar a classificação e avaliar o desempenho do modelo. A Árvore de Decisão é um algoritmo de aprendizado supervisionado que divide os dados em subconjuntos baseados em condições de atributos, criando uma estrutura em forma de árvore. Cada nó interno representa uma condição de atributo, cada ramo representa o resultado da condição, e cada folha representa uma classe ou valor final. Este método é intuitivo e fácil de interpretar, mas pode ser propenso a overfitting se não for devidamente podado."
      ],
      "metadata": {
        "id": "MCiNV3nNW_nX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRyQ6-yBVQaA"
      },
      "source": [
        "* Inicialização e ajuste de um classificador de árvore de decisão aos dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpHfCVu1VQaA"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clfDT = DecisionTreeClassifier(criterion='gini',\n",
        "                             splitter='best',\n",
        "                             max_depth=None,\n",
        "                             min_samples_split=2,\n",
        "                             min_samples_leaf=1,\n",
        "                             min_weight_fraction_leaf=0.0,\n",
        "                             max_features=None,\n",
        "                             random_state=42,\n",
        "                             max_leaf_nodes=None,\n",
        "                             min_impurity_decrease=0.0,\n",
        "                             class_weight=None,\n",
        "                             ccp_alpha=0.0,\n",
        "                             monotonic_cst=None)\n",
        "clfDT.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpNBCjTrVQaA"
      },
      "source": [
        "* Cálculo dos indicadores do classificador usando os dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rchawdWpVQaA"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, clfDT.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bekQQF8mVQaA"
      },
      "source": [
        "* Cálculo e exibição da matriz de confusão usando os rótulos verdadeiros e preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LgxXJVuVQaA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmDT = confusion_matrix(y_test, clfDT.predict(X_test))\n",
        "print('Matriz de Confusão:')\n",
        "print(cmDT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW5ezdobVQaA"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thuz5kS_VQaA"
      },
      "source": [
        "##### Nas células a seguir, estamos realizando classificação utilizando o algoritmo K-Vizinhos Mais Próximos (KNN) juntamente com a técnica de validação cruzada para avaliar o desempenho do modelo. O KNN é um algoritmo de aprendizado supervisionado que classifica os pontos de dados com base na classe majoritária dos seus vizinhos mais próximos.  \n",
        "\n",
        "1) Importação de Bibliotecas: Primeiramente, importamos a classe `KNeighborsClassifier` do módulo `neighbors` do `scikit-learn`, além do `cross_val_score` para realizar validação cruzada e `matplotlib.pyplot` para visualização.\n",
        "2) Inicialização do Classificador: Instanciamos o classificador KNN com os parâmetros padrão.\n",
        "3) Validação Cruzada: Utilizamos a função `cross_val_score` para avaliar o desempenho do modelo através da validação cruzada. Essa função divide os dados em _k_ partes iguais e, para cada iteração, uma parte é usada como conjunto de teste enquanto as outras partes são usadas como conjunto de treinamento.\n",
        "4) Avaliação do Desempenho: Calculamos a média dos escores de validação cruzada para avaliar o desempenho do modelo.\n",
        "5) Visualização dos Resultados: Utilizamos `matplotlib.pyplot` para plotar um gráfico que mostra como o desempenho do modelo varia com o número de vizinhos.\n",
        "Essas etapas nos ajudarão a entender como o desempenho do modelo KNN é afetado pelo número de vizinhos e a escolher o melhor valor para esse parâmetro.  \n",
        "É recomendável que o valor de K não seja maior do que o numero de features usadas, portanto, vamos limitar a iteração ao número de colunas em _*X*_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmV3q9CPVQaB"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCyXAqpZVQaB"
      },
      "outputs": [],
      "source": [
        "score_rate = []\n",
        "\n",
        "for i in tqdm(range(1,X_train.shape[1], 2)):\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    accuracy = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "    score_rate.append(accuracy)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,X_train.shape[1], 2), score_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
        "\n",
        "plt.title('Accuracy VS K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67Qv4fwVQaB"
      },
      "source": [
        "* Usando o método do cotovelo, podemos ver que o ponto ótimo para treinamento é com 5 vizinhos.\n",
        "* O próximo passo é a inicialização e ajuste de um classificador de KNN aos dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgkFg3N1VQaB"
      },
      "outputs": [],
      "source": [
        "clfKNN = KNeighborsClassifier(\n",
        "    n_neighbors=5,\n",
        "    weights='uniform',\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    p=2,\n",
        "    metric='minkowski',\n",
        "    metric_params=None,\n",
        "    n_jobs=None)\n",
        "\n",
        "clfKNN.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wN77Z1OVQaB"
      },
      "source": [
        "* Cálculo dos indicadores do classificador usando os dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddysAkkcVQaB"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, clfKNN.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AP3MyN5VQaB"
      },
      "source": [
        "* Cálculo e exibição da matriz de confusão usando os rótulos verdadeiros e preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_4PaNM7VQaB"
      },
      "outputs": [],
      "source": [
        "cmKNN = confusion_matrix(y_test, clfKNN.predict(X_test))\n",
        "print('Matriz de Confusão:')\n",
        "print(cmKNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "gAaCbyrQVY8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estamos utilizando o algoritmo Random Forest para realizar a classificação e avaliar o desempenho do modelo. O Random Forest é um algoritmo de aprendizado supervisionado que utiliza um conjunto de árvores de decisão, onde cada árvore é construída a partir de um subconjunto aleatório de dados e características. A classificação final é determinada pela votação majoritária das classes preditas por todas as árvores. Esta abordagem tende a melhorar a precisão do modelo e reduzir o risco de overfitting."
      ],
      "metadata": {
        "id": "TnMmIFJnXEBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Importação do módulo"
      ],
      "metadata": {
        "id": "WHF2oF-6XPAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "cCWPABIYXN4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koCPbXCTXvHj"
      },
      "source": [
        "* O próximo passo é a inicialização e ajuste de um classificador de random forest aos dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clfRF = RandomForestClassifier(random_state=11)\n",
        "\n",
        "clfRF.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "G1L1YmLtXZWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cálculo dos indicadores do classificador usando os dados de teste."
      ],
      "metadata": {
        "id": "_-cHA040Xzb3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik4fyvAtX_s2"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, clfRF.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIG8RgfCYET7"
      },
      "source": [
        "* Cálculo e exibição da matriz de confusão usando os rótulos verdadeiros e preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWsZQSiBYGkA"
      },
      "outputs": [],
      "source": [
        "cmRF = confusion_matrix(y_test, clfRF.predict(X_test))\n",
        "print('Matriz de Confusão:')\n",
        "print(cmRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CryHBheBVQaB"
      },
      "source": [
        "## Conclusão\n",
        "  \n",
        "Com base nos scores fornecidos, parece que o modelo Decision Tree apresentou um desempenho superior ao modelo KNN para o problema específico em questão.  \n",
        "\n",
        "* O _F1-score_ do modelo Decision Tree é mais alto do que o do modelo KNN para ambas as classes. Isso sugere que o modelo de árvore de decisão tem um melhor equilíbrio entre precisão e recall.\n",
        "* Tanto os socres de _Recall_ quanto o de _Precision_ do modelo Decision Tree são mais altos do que os do modelo KNN para ambas as classes, mas a diferença não é muito significativa - o modelo KNN apresenta uma precisão um pouco mais baixa para a classe 0, mas uma precisão comparável para a classe 1. No entanto, o recall para a classe 0 é significativamente mais baixo em comparação com o modelo de árvore de decisão, enquanto o recall para a classe 1 é um pouco mais alto.\n",
        "* A acurácia geral do modelo KNN é de 0.81, o que é um pouco menor do que a do modelo Decision Tree (0.87). No entanto, as diferenças não são tão significativas.\n",
        "  \n",
        "Com base nessas observações, podemos concluir que, para o conjunto de dados e o problema específico em questão, o modelo Decision Tree parece ser uma escolha ligeiramente melhor em termos de equilíbrio entre precisão, recall e acurácia.   \n",
        "Importante ressaltar que em nenhum dos modelos, a parametrização foi alvo de estudo até o momento.  Trabalhos futuros podem considerar uma otimização como alvo de estudo, além do balanceamento do conjunto de treino/teste, utilizando técnicas de undersampling ou oversamplig, data augmentation ou SMOTE.\n",
        "  \n",
        "Além disso, outras conclusões podem ser destacadas:\n",
        "* **Interpretabilidade**: Se for uma preocupação importante e o conjunto de dados não for extremamente grande, o modelo Decision Tree terá uma vantagem significativa.\n",
        "* **Tempo de Treinamento**: o modelo Decision Tree geralmente levará menos tempo para treinar do que o modelo KNN.\n",
        "* **Escalabilidade**: o KNN pode ser preferível, especialmente em conjuntos de dados menores ou com dimensionalidade moderada."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}